{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEIxLbmXmMysF5J2ieE21t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caiocesarcosta/transfer_learning_projeto1/blob/main/transfer_learning_projeto1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IY754SSB2S2P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47557bdf-81b6-428d-f383-6ab42015dd42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERRO: Imagem de teste não encontrada. Verifique o caminho e se há imagens nas pastas train/cats e train/dogs.\n",
            "Found 1999 images belonging to 3 classes.\n",
            "Found 2000 images belonging to 3 classes.\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 639ms/step - accuracy: 0.4910 - loss: -3632594.2500 - val_accuracy: 0.5000 - val_loss: -77554232.0000\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.11/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5050 - val_loss: -76891544.0000\n",
            "Epoch 3/50\n",
            "\u001b[1m 82/125\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 567ms/step - accuracy: 0.4604 - loss: -154899296.0000"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Dimensões das imagens\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "# Caminhos para os dados (ajuste estes caminhos conforme necessário)\n",
        "train_data_dir = '/content/data/train'\n",
        "validation_data_dir = '/content/data/validation'\n",
        "nb_train_samples = 2000\n",
        "nb_validation_samples = 800\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "\n",
        "# Verifica o formato da imagem e define input_shape (importante verificar se a imagem existe!)\n",
        "try:\n",
        "    img = image.load_img(f'{train_data_dir}/cats/cat.0.jpg') # ou qualquer imagem na pasta de treino.\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    input_shape = (img_width, img_height, 3) if tf.keras.backend.image_data_format() == 'channels_last' else (3, img_width, img_height)\n",
        "except FileNotFoundError:\n",
        "    print(\"ERRO: Imagem de teste não encontrada. Verifique o caminho e se há imagens nas pastas train/cats e train/dogs.\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"ERRO ao carregar imagem: {e}\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), input_shape=input_shape),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(32, (3, 3)),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3)),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(64),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1),  # Camada de saída para classificação binária\n",
        "    Activation('sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# ImageDataGenerator para aumento de dados\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "# Geração de batches de imagens\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "# Treinamento do modelo\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "model.save_weights('first_try.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YljXBLG08OHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dkEQ8OgKquOj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}